{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfBOUA9y9QyMthCAo1DZFK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/23023339-JaydenPang/FYP_Rally/blob/main/Gemini_API_(Use_This).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Install dependencies ===\n",
        "!pip install -q google-generativeai pandas gspread gspread-dataframe beautifulsoup4\n",
        "\n",
        "# === Imports and authentication ===\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import google.generativeai as genai\n",
        "from google.colab import auth, userdata\n",
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "from google.auth import default\n",
        "from googleapiclient.discovery import build\n",
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# === Configure Gemini ===\n",
        "gemini_key = userdata.get('GeminiAPIKey')\n",
        "if not gemini_key:\n",
        "    raise ValueError(\"❌ Gemini API key not found. Use userdata.set('GeminiAPIKey', 'your-key')\")\n",
        "\n",
        "genai.configure(api_key=gemini_key)\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\", generation_config={\n",
        "    \"temperature\": 0.2, \"top_p\": 0.9, \"top_k\": 50, \"max_output_tokens\": 800\n",
        "})\n",
        "\n",
        "# === Sheet utilities ===\n",
        "def enable_text_wrap(spreadsheet_id, worksheet_name, num_columns):\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "    sheet_metadata = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()\n",
        "    sheet_id = next((s['properties']['sheetId'] for s in sheet_metadata['sheets'] if s['properties']['title'] == worksheet_name), None)\n",
        "    if sheet_id is None:\n",
        "        raise ValueError(f\"Worksheet '{worksheet_name}' not found.\")\n",
        "    requests = [{\n",
        "        \"repeatCell\": {\n",
        "            \"range\": {\n",
        "                \"sheetId\": sheet_id,\n",
        "                \"startRowIndex\": 0,\n",
        "                \"startColumnIndex\": 0,\n",
        "                \"endColumnIndex\": num_columns\n",
        "            },\n",
        "            \"cell\": {\n",
        "                \"userEnteredFormat\": {\n",
        "                    \"wrapStrategy\": \"WRAP\"\n",
        "                }\n",
        "            },\n",
        "            \"fields\": \"userEnteredFormat.wrapStrategy\"\n",
        "        }\n",
        "    }]\n",
        "    service.spreadsheets().batchUpdate(\n",
        "        spreadsheetId=spreadsheet_id, body={\"requests\": requests}\n",
        "    ).execute()\n",
        "\n",
        "def append_to_sheet(sheet_name, worksheet_name, new_df):\n",
        "    try:\n",
        "        spreadsheet = gc.open(sheet_name)\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        spreadsheet = gc.create(sheet_name)\n",
        "        spreadsheet.share('', perm_type='anyone', role='writer')\n",
        "    try:\n",
        "        worksheet = spreadsheet.worksheet(worksheet_name)\n",
        "    except gspread.exceptions.WorksheetNotFound:\n",
        "        worksheet = spreadsheet.add_worksheet(title=worksheet_name, rows=\"1000\", cols=\"30\")\n",
        "    existing_df = get_as_dataframe(worksheet).dropna(how='all')\n",
        "    updated_df = pd.concat([existing_df, new_df], ignore_index=True) if not existing_df.empty else new_df\n",
        "    set_with_dataframe(worksheet, updated_df)\n",
        "    enable_text_wrap(spreadsheet.id, worksheet_name, len(updated_df.columns))\n",
        "    print(f\"✅ Appended to: https://docs.google.com/spreadsheets/d/{spreadsheet.id}\")\n",
        "\n",
        "# === Social media extraction utility ===\n",
        "def extract_social_media_links(html, base_url):\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    links = soup.find_all(\"a\", href=True)\n",
        "\n",
        "    social_media = {\"instagram\": \"Not found\", \"facebook\": \"Not found\", \"other\": []}\n",
        "\n",
        "    for link in links:\n",
        "        href = link['href'].strip()\n",
        "        if \"instagram.com\" in href and social_media[\"instagram\"] == \"Not found\":\n",
        "            social_media[\"instagram\"] = href\n",
        "        elif \"facebook.com\" in href and social_media[\"facebook\"] == \"Not found\":\n",
        "            social_media[\"facebook\"] = href\n",
        "        elif any(x in href for x in [\"tiktok.com\", \"youtube.com\", \"linkedin.com\", \"twitter.com\", \"x.com\"]):\n",
        "            social_media[\"other\"].append(href)\n",
        "\n",
        "    if not social_media[\"other\"]:\n",
        "        social_media[\"other\"] = \"Not found\"\n",
        "\n",
        "    return social_media\n",
        "\n",
        "# === LLM Prompt Tuning ===\n",
        "# === Together AI Inference ===\n",
        "def call_together(prompt, model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", temperature=0.2, max_tokens=800):\n",
        "    together_key = userdata.get(\"TogetherAPIKey\")\n",
        "    if not together_key:\n",
        "        raise ValueError(\"❌ Together API key not found. Use userdata.set('TogetherAPIKey', 'your-key')\")\n",
        "\n",
        "    url = \"https://api.together.xyz/v1/chat/completions\"\n",
        "    headers = {\"Authorization\": f\"Bearer {together_key}\", \"Content-Type\": \"application/json\"}\n",
        "    payload = {\n",
        "        \"model\": model_name,\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "\n",
        "    start_time = time.time()\n",
        "    start_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    try:\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "        data = response.json()\n",
        "        text = data[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "        prompt_tokens = data[\"usage\"][\"prompt_tokens\"]\n",
        "        output_tokens = data[\"usage\"][\"completion_tokens\"]\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"prompt\": prompt,\n",
        "            \"response\": text,\n",
        "            \"prompt_tokens\": prompt_tokens,\n",
        "            \"output_tokens\": output_tokens,\n",
        "            \"total_tokens\": prompt_tokens + output_tokens,\n",
        "            \"start_time\": start_timestamp,\n",
        "            \"end_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            \"response_time\": round(time.time() - start_time, 2)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"prompt\": prompt,\n",
        "            \"response\": f\"❌ Together AI error: {e}\",\n",
        "            \"prompt_tokens\": 0,\n",
        "            \"output_tokens\": 0,\n",
        "            \"total_tokens\": 0,\n",
        "            \"start_time\": start_timestamp,\n",
        "            \"end_time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            \"response_time\": round(time.time() - start_time, 2)\n",
        "        }\n",
        "\n",
        "# === LLM Prompt Tuning with Gemini, Groq, and Together ===\n",
        "def tune_prompt(prompt_for_logging, label, original_output, qna_or_review, prompt_for_generation=None):\n",
        "    if prompt_for_generation is None:\n",
        "        prompt_for_generation = prompt_for_logging\n",
        "\n",
        "    results = []\n",
        "    start_time = time.time()\n",
        "    start_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    # --- Original Gemini Output (uses prompt_for_generation)\n",
        "    input_str = f\"{prompt_for_generation}\\n\\nAnswer: \\\"{qna_or_review}\\\"\"\n",
        "    try:\n",
        "        gemini_out = model.generate_content(input_str).text.strip()\n",
        "        gemini_tokens = model.count_tokens(gemini_out).total_tokens\n",
        "        prompt_tokens = model.count_tokens(prompt_for_logging).total_tokens\n",
        "    except Exception as e:\n",
        "        gemini_out, gemini_tokens, prompt_tokens = f\"❌ Gemini error: {e}\", 0, 0\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": f\"Gemini (Original {label} Prompt)\",\n",
        "        \"Input Prompt\": prompt_for_logging,\n",
        "        \"Input\": qna_or_review,\n",
        "        \"Response\": gemini_out,\n",
        "        \"Input Tokens\": prompt_tokens,\n",
        "        \"Output Tokens\": gemini_tokens,\n",
        "        \"Total Tokens\": prompt_tokens + gemini_tokens,\n",
        "        \"Start Time\": start_timestamp,\n",
        "        \"End Time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        \"Response Time (s)\": round(time.time() - start_time, 2)\n",
        "    })\n",
        "\n",
        "    # --- Together AI Prompt Improvement → Gemini\n",
        "    if use_together:\n",
        "        try:\n",
        "            optimization_instruction = (\n",
        "                \"Improve the following prompt to generate more accurate and complete responses from Gemini, \"\n",
        "                \"while reducing the total token cost. Keep the original output structure and required JSON keys unchanged. \"\n",
        "                \"Remove any unnecessary words or repetition. Avoid verbose instructions. Be concise but clear.\\n\\n\"\n",
        "            )\n",
        "            together_result = call_together(optimization_instruction + prompt_for_logging)\n",
        "            improved_prompt = together_result[\"response\"]\n",
        "            improved_input = f\"{improved_prompt}\\n\\nAnswer: \\\"{qna_or_review}\\\"\"\n",
        "            gemini_out_together = model.generate_content(improved_input).text.strip()\n",
        "            gemini_tokens = model.count_tokens(gemini_out_together).total_tokens\n",
        "            prompt_tokens = model.count_tokens(improved_prompt).total_tokens\n",
        "            results.append({\n",
        "                \"Model\": f\"Gemini (Together-Tuned {label} Prompt)\",\n",
        "                \"Input Prompt\": improved_prompt,\n",
        "                \"Input\": qna_or_review,\n",
        "                \"Response\": gemini_out_together,\n",
        "                \"Input Tokens\": prompt_tokens,\n",
        "                \"Output Tokens\": gemini_tokens,\n",
        "                \"Total Tokens\": prompt_tokens + gemini_tokens,\n",
        "                \"Start Time\": together_result[\"start_time\"],\n",
        "                \"End Time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"Response Time (s)\": together_result[\"response_time\"]\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Together AI error for {label} Prompt: {e}\")\n",
        "\n",
        "    # --- Groq Prompt Improvement → Gemini\n",
        "    if use_groq:\n",
        "        try:\n",
        "            groq_key = userdata.get(\"GroqAPIKey\")\n",
        "            optimization_instruction = (\n",
        "                \"Improve the following prompt to generate more accurate and complete responses from Gemini, \"\n",
        "                \"while reducing the total token cost. Keep the original output structure and required JSON keys unchanged. \"\n",
        "                \"Remove any unnecessary words or repetition. Avoid verbose instructions. Be concise but clear.\\n\\n\"\n",
        "            )\n",
        "            groq_resp = requests.post(\n",
        "                \"https://api.groq.com/openai/v1/chat/completions\",\n",
        "                headers={\"Authorization\": f\"Bearer {groq_key}\", \"Content-Type\": \"application/json\"},\n",
        "                json={\n",
        "                    \"model\": \"llama3-8b-8192\",\n",
        "                    \"messages\": [{\"role\": \"user\", \"content\": optimization_instruction + prompt_for_logging}],\n",
        "                    \"temperature\": temperature, \"max_tokens\": 800\n",
        "                }\n",
        "            ).json()\n",
        "            improved_prompt = groq_resp[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "            if label == \"Business\":\n",
        "                res = requests.get(qna_or_review, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "                page_html = res.text\n",
        "                social_links = extract_social_media_links(page_html, qna_or_review)\n",
        "                enriched_prompt = (\n",
        "                    f\"{improved_prompt}\\n\\n\"\n",
        "                    f\"## Extracted Social Media Links:\\n{json.dumps(social_links, indent=2)}\\n\\n\"\n",
        "                    f\"## Truncated HTML Content:\\n{page_html[:10000]}\"\n",
        "                )\n",
        "            else:\n",
        "                enriched_prompt = f\"{improved_prompt}\\n\\nAnswer: \\\"{qna_or_review}\\\"\"\n",
        "\n",
        "            gemini_out_groq = model.generate_content(enriched_prompt).text.strip()\n",
        "            gemini_tokens_groq = model.count_tokens(gemini_out_groq).total_tokens\n",
        "            prompt_tokens = model.count_tokens(improved_prompt).total_tokens\n",
        "            results.append({\n",
        "                \"Model\": f\"Gemini (Groq-Tuned {label} Prompt)\",\n",
        "                \"Input Prompt\": improved_prompt,\n",
        "                \"Input\": qna_or_review,\n",
        "                \"Response\": gemini_out_groq,\n",
        "                \"Input Tokens\": prompt_tokens,\n",
        "                \"Output Tokens\": gemini_tokens_groq,\n",
        "                \"Total Tokens\": prompt_tokens + gemini_tokens_groq,\n",
        "                \"Start Time\": start_timestamp,\n",
        "                \"End Time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                \"Response Time (s)\": round(time.time() - start_time, 2)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Groq error for {label} Prompt: {e}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "\n",
        "# === User Inputs ===\n",
        "review_text = \"question\\\": \\\"What improvement would you like to see in our OG Gold membership?\\\", \\t\\t\\t\\\"question_type\\\": \\\"long\\\",       \\\"answer\\\": \\\"I don’t have anything in particular to suggest. Everything has been very very very very good so far with the OG Gold membership. I think is good and don't need to change at the moment.\\\"\"  #@param {type:\"string\"}\n",
        "golden_prompt = \"As Rally AI's evaluation assistant, evaluate answers with:  - Usefulness_score: 0-2 (poor, med, good) - Usefulness_reason (<21 words) - Authenticity_score: 0-5 (not gen, maybe gen, gen) - Authenticity_reason (<21 words)  Identify answers to improve with low usefulness or authenticity scores.  Output JSON:  ```json {   \\\"review\\\": {     \\\"Question 1\\\": {       \\\"Usefulness_score\\\": 0,       \\\"Usefulness_reason\\\": \\\"\\\",       \\\"Authenticity_score\\\": 0,       \\\"Authenticity_reason\\\": \\\"\\\"     },     \\\"...\\\": {       ...     }   },   \\\"Answers_to_improve\\\": [\\\"Question 2\\\", ...],   \\\"Feedback\\\": \\\"\\\" } ```\"  #@param {type:\"string\"}\n",
        "consumer_profiling_prompt = \"\"  #@param {type:\"string\"}\n",
        "business_profiling_prompt = \"\"  #@param {type:\"string\"}\n",
        "consumer_qna = \"\"  #@param {type:\"string\"}\n",
        "company_link = \"\"  #@param {type:\"string\"}\n",
        "use_groq = True  #@param {type:\"boolean\"}\n",
        "use_together = True #@param {type:\"boolean\"}\n",
        "show_all_outputs = True  #@param {type:\"boolean\"}\n",
        "log_to_sheets = True  #@param {type:\"boolean\"}\n",
        "temperature = 0.2  #@param {type:\"slider\", min:0.0, max:1.0, step:0.1}\n",
        "\n",
        "# === Business prompt enhancement with scraped web data ===\n",
        "try:\n",
        "    headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
        "}\n",
        "    res = requests.get(company_link, headers=headers, timeout=10)\n",
        "\n",
        "    if res.status_code == 200:\n",
        "        page_html = res.text\n",
        "        social_links = extract_social_media_links(page_html, company_link)\n",
        "        social_json = json.dumps(social_links, indent=2)\n",
        "        business_prompt_with_links = (\n",
        "            f\"{business_profiling_prompt}\\n\\n\"\n",
        "            f\"## Extracted Social Media Links:\\n{social_json}\\n\\n\"\n",
        "            f\"## Truncated HTML Content:\\n{page_html[:10000]}\"\n",
        "        )\n",
        "    else:\n",
        "        print(f\"❌ Failed to load website: {company_link}\")\n",
        "        business_prompt_with_links = business_profiling_prompt\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error fetching company page: {e}\")\n",
        "    business_prompt_with_links = business_profiling_prompt\n",
        "\n",
        "# Keep original prompt separate for correct logging\n",
        "business_prompt_only = business_profiling_prompt\n",
        "\n",
        "# === Run prompt evaluations only if input is provided ===\n",
        "eval_df = pd.DataFrame()\n",
        "consumer_df = pd.DataFrame()\n",
        "business_df = pd.DataFrame()\n",
        "\n",
        "if review_text.strip():\n",
        "    eval_df = tune_prompt(golden_prompt, \"Golden\", \"\", review_text)\n",
        "\n",
        "if consumer_qna.strip():\n",
        "    consumer_df = tune_prompt(consumer_profiling_prompt, \"Consumer\", \"\", consumer_qna)\n",
        "\n",
        "if company_link.strip():\n",
        "    business_df = tune_prompt(\n",
        "        prompt_for_logging=business_prompt_only,\n",
        "        label=\"Business\",\n",
        "        original_output=\"\",\n",
        "        qna_or_review=company_link,\n",
        "        prompt_for_generation=business_prompt_with_links\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# === Log results only if corresponding input is not empty ===\n",
        "if log_to_sheets:\n",
        "    if not eval_df.empty:\n",
        "        append_to_sheet(\"Gemini_Responses\", \"Sheet1\", eval_df)\n",
        "    if not consumer_df.empty:\n",
        "        append_to_sheet(\"Consumer Profiling\", \"Sheet1\", consumer_df)\n",
        "    if not business_df.empty:\n",
        "        append_to_sheet(\"Business Profiling\", \"Sheet1\", business_df)\n",
        "\n",
        "\n",
        "# === Display ===\n",
        "if show_all_outputs:\n",
        "    print(\"\\n📊 Prompt Evaluation Summary\")\n",
        "    for df in [eval_df, consumer_df, business_df]:\n",
        "        for row in df.itertuples():\n",
        "            print(f\"\\n==== {row.Model} ====\")\n",
        "            print(f\"Prompt: {row._2[:200]}...\\nResponse: {row.Response[:500]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yk_WHZrXh8lc",
        "outputId": "ddae8228-67bf-4fb3-87f9-b44707fdd4da",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error fetching company page: Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
            "✅ Appended to: https://docs.google.com/spreadsheets/d/1v10PU7lJ0BLs45zE98DtAE9wkgwKXZi925u2YGD_CV4\n",
            "\n",
            "📊 Prompt Evaluation Summary\n",
            "\n",
            "==== Gemini (Original Golden Prompt) ====\n",
            "Prompt: As Rally AI's evaluation assistant, evaluate answers with:  - Usefulness_score: 0-2 (poor, med, good) - Usefulness_reason (<21 words) - Authenticity_score: 0-5 (not gen, maybe gen, gen) - Authenticity...\n",
            "Response: ```json\n",
            "{\n",
            "  \"review\": {\n",
            "    \"What improvement would you like to see in our OG Gold membership?\": {\n",
            "      \"Usefulness_score\": 0,\n",
            "      \"Usefulness_reason\": \"The answer doesn't provide any suggestions for improvement, rendering it unhelpful.\",\n",
            "      \"Authenticity_score\": 5,\n",
            "      \"Authenticity_reason\": \"The response sounds like a genuine user experience, expressing satisfaction.\"\n",
            "    }\n",
            "  },\n",
            "  \"Answers_to_improve\": [\n",
            "    \"What improvement would you like to see in our OG Gold membership?\"\n",
            "  ],\n",
            "  \"Fe\n",
            "\n",
            "==== Gemini (Together-Tuned Golden Prompt) ====\n",
            "Prompt: As Rally AI's evaluator, assess answers with:\n",
            "\n",
            "* Usefulness: 0-2 (poor, med, good)\n",
            "* Usefulness reason (<21 words)\n",
            "* Authenticity: 0-5 (not gen, maybe gen, gen)\n",
            "* Authenticity reason (<21 words)\n",
            "\n",
            "Iden...\n",
            "Response: ```json\n",
            "{\n",
            "  \"assessment\": {\n",
            "    \"Q1\": {\n",
            "      \"Usefulness\": 0,\n",
            "      \"Usefulness_reason\": \"The answer doesn't provide any suggestions for improvement, stating everything is good.\",\n",
            "      \"Authenticity\": 5,\n",
            "      \"Authenticity_reason\": \"The response is a genuine expression of satisfaction, without any signs of being fabricated.\"\n",
            "    }\n",
            "  },\n",
            "  \"improve\": [],\n",
            "  \"feedback\": \"\"\n",
            "}\n",
            "```\n",
            "\n",
            "==== Gemini (Groq-Tuned Golden Prompt) ====\n",
            "Prompt: Here is an improved version of the prompt:\n",
            "\n",
            "Evaluate answers with:\n",
            "\n",
            "* Usefulness_score: 0-2 (poor, med, good)\n",
            "* Usefulness_reason (<21 words)\n",
            "* Authenticity_score: 0-5 (not gen, maybe gen, gen)\n",
            "* Auth...\n",
            "Response: ```json\n",
            "{\n",
            "  \"review\": {\n",
            "    \"answer_1\": {\n",
            "      \"Usefulness_score\": 0,\n",
            "      \"Usefulness_reason\": \"The answer provides no specific suggestions for improvement, stating everything is already good.\",\n",
            "      \"Authenticity_score\": 5,\n",
            "      \"Authenticity_reason\": \"The response sounds like a genuine, albeit unhelpful, customer opinion.\"\n",
            "    }\n",
            "  },\n",
            "  \"Answers_to_improve\": [\"answer_1\"],\n",
            "  \"Feedback\": \"The answer is not helpful because it doesn't offer any constructive criticism. Encourage the user to thi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Install dependencies ===\n",
        "!pip install -q google-generativeai pandas gspread gspread-dataframe\n",
        "\n",
        "# === Imports and authentication ===\n",
        "import time\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import google.generativeai as genai\n",
        "from google.colab import auth, userdata\n",
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "from google.auth import default\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# === Authenticate ===\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# === Configure Gemini ===\n",
        "gemini_key = userdata.get('GeminiAPIKey')\n",
        "if not gemini_key:\n",
        "    raise ValueError(\"❌ Gemini API key not found. Use userdata.set('GeminiAPIKey', 'your-key')\")\n",
        "\n",
        "genai.configure(api_key=gemini_key)\n",
        "model = genai.GenerativeModel(\"gemini-2.0-flash\", generation_config={\n",
        "    \"temperature\": 0.2, \"top_p\": 0.9, \"top_k\": 50, \"max_output_tokens\": 800\n",
        "})\n",
        "\n",
        "def enable_text_wrap(spreadsheet_id, sheet_name, num_columns):\n",
        "    service = build('sheets', 'v4', credentials=creds)\n",
        "    sheet_metadata = service.spreadsheets().get(spreadsheetId=spreadsheet_id).execute()\n",
        "    sheet_id = next(s['properties']['sheetId'] for s in sheet_metadata['sheets'] if s['properties']['title'] == sheet_name)\n",
        "\n",
        "    requests = [{\n",
        "        \"repeatCell\": {\n",
        "            \"range\": {\n",
        "                \"sheetId\": sheet_id,\n",
        "                \"startRowIndex\": 0,\n",
        "                \"endColumnIndex\": num_columns\n",
        "            },\n",
        "            \"cell\": {\n",
        "                \"userEnteredFormat\": {\n",
        "                    \"wrapStrategy\": \"WRAP\"\n",
        "                }\n",
        "            },\n",
        "            \"fields\": \"userEnteredFormat.wrapStrategy\"\n",
        "        }\n",
        "    }]\n",
        "    service.spreadsheets().batchUpdate(spreadsheetId=spreadsheet_id, body={\"requests\": requests}).execute()\n",
        "\n",
        "\n",
        "# === Sheet utilities ===\n",
        "def append_to_sheet(sheet_name, worksheet_name, new_df):\n",
        "    try:\n",
        "        spreadsheet = gc.open(sheet_name)\n",
        "        created = False\n",
        "    except gspread.SpreadsheetNotFound:\n",
        "        spreadsheet = gc.create(sheet_name)\n",
        "        spreadsheet.share('', perm_type='anyone', role='writer')\n",
        "        created = True\n",
        "\n",
        "    try:\n",
        "        worksheet = spreadsheet.worksheet(worksheet_name)\n",
        "    except gspread.WorksheetNotFound:\n",
        "        worksheet = spreadsheet.add_worksheet(title=worksheet_name, rows=100, cols=20)\n",
        "\n",
        "    existing_df = get_as_dataframe(worksheet, evaluate_formulas=True).dropna(how='all')\n",
        "    updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
        "    set_with_dataframe(worksheet, updated_df)\n",
        "\n",
        "    # ✅ Wrap text in all columns\n",
        "    enable_text_wrap(spreadsheet.id, worksheet_name, len(updated_df.columns))\n",
        "\n",
        "    sheet_url = f\"https://docs.google.com/spreadsheets/d/{spreadsheet.id}\"\n",
        "    if created:\n",
        "        print(f\"📄 Created new Google Sheet: {sheet_url}\")\n",
        "    else:\n",
        "        print(f\"📄 Updated existing Google Sheet: {sheet_url}\")\n",
        "    print(f\"🔗 View Full Results: {sheet_url}\")\n",
        "    return spreadsheet.id\n",
        "\n",
        "\n",
        "# === User Inputs ===\n",
        "qna_profile = \" Jayden’ Responses What is your age group? → 18-24  What is your gender? → Male  Where do you live? → Yew Tee, Singapore  What is your occupation? → Student  What is your highest level of education? → Polytechnic Diploma  What is your monthly household income bracket? → S$4,000–S$6,000   Dining Behaviour How often do you dine out each week? → 3–4 times a week  How much do you usually spend on a typical meal? → Around S$12–S$20  How do you usually choose where to eat? → I read Google or TikTok reviews and check what’s trending.  Do you prefer dining alone, with friends, or family? → Mostly with friends  How far are you willing to travel for a good meal? → Up to 30 minutes on MRT   Food Preferences & Psychographics What are your top 3 favourite cuisines? → Japanese, Thai, and Korean  Are there any cuisines you avoid or dislike? → Not a big fan of Mediterranean food  How sensitive are you to food prices when choosing a place to eat? → Somewhat sensitive — I don’t like overpaying unless it’s worth it  What matters most when dining out? → Taste and value for money  How likely are you to try new foods or restaurants? → Very likely — I enjoy discovering new places   Engagement & Tech Use How often do you leave reviews or feedback after eating out? → Occasionally, when the experience is really good or bad  Do you use food delivery apps or dining loyalty programmes? → Yes, I use GrabFood and occasionally Chope for bookings  How often do you complete quests on Rally? → Once or twice a month  What motivates you to complete quests? → Mainly the rewards and to try new places with discounts\"  #@param {type:\"string\", label:\"Consumer QnA Profile\"}\n",
        "behaviour_questions = \"Behavioral Questions When choosing a place to eat, what platforms or tools do you usually use to research or decide? (e.g., Google reviews, TikTok, Instagram, food blogs, word of mouth)  How do your dining preferences change depending on who you're eating with (friends, family, alone)? (e.g., spend more, choose different cuisine, go to casual vs formal spots)  Describe a recent time when you were impressed or disappointed by a dining experience. What made it memorable? (Look for triggers of satisfaction or dissatisfaction)  What influences you more when trying a new restaurant: social media trends or personal recommendations? Why?  Have you ever returned to a restaurant because of a loyalty reward or promotion? What was the offer?  When faced with two restaurants—one more expensive but better-rated, and one cheaper but average—which would you choose and why?  How do you usually discover new food spots? Do you actively search, or find them spontaneously?  Tell us about a time you tried a cuisine you weren’t familiar with. What motivated you to try it? (e.g., curiosity, peer influence, trending)  When using food apps like GrabFood or Chope, what features do you value the most? (e.g., ease of use, discounts, ratings, location filters)  If you received a mission/quest offering 30% off at a new restaurant 25 minutes away, what factors would influence your decision to go or not? (e.g., travel time, cuisine, price, company, timing)\"  #@param {type:\"string\", label:\"Behavioural Questions\"}\n",
        "\n",
        "# === Generate and Log Gemini Answer ===\n",
        "result_df = pd.DataFrame()\n",
        "sheet_url = \"\"\n",
        "\n",
        "if qna_profile.strip() and behaviour_questions.strip():\n",
        "    input_prompt = (\n",
        "        \"You are Rally AI. Based on the following consumer profile (QnA), answer the behavioural questions that follow.\\n\\n\"\n",
        "        f\"## QnA Profile:\\n{qna_profile}\\n\\n\"\n",
        "        f\"## Behavioural Questions:\\n{behaviour_questions}\"\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    start_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(input_prompt).text.strip()\n",
        "        output_tokens = model.count_tokens(response).total_tokens\n",
        "        input_tokens = model.count_tokens(input_prompt).total_tokens\n",
        "    except Exception as e:\n",
        "        response = f\"❌ Gemini error: {e}\"\n",
        "        output_tokens = 0\n",
        "        input_tokens = 0\n",
        "\n",
        "    result_df = pd.DataFrame([{\n",
        "        \"QnA Profile\": qna_profile,\n",
        "        \"Behavioural Questions\": behaviour_questions,\n",
        "        \"Gemini Response\": response,\n",
        "        \"Input Tokens\": input_tokens,\n",
        "        \"Output Tokens\": output_tokens,\n",
        "        \"Start Time\": start_timestamp,\n",
        "        \"End Time\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        \"Response Time (s)\": round(time.time() - start_time, 2)\n",
        "    }])\n",
        "\n",
        "    sheet_url = append_to_sheet(\"consumer_testing\", \"Sheet1\", result_df)\n",
        "\n",
        "# === Display ===\n",
        "if not result_df.empty:\n",
        "    print(\"\\n📊 Gemini Response Summary:\")\n",
        "    print(result_df[['Gemini Response']].iloc[0][0][:1000])\n",
        "    print(f\"\\n🔗 View Full Results: {sheet_url}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6BjShS0G-917"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}